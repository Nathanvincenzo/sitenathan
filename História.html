
<h1>História <br> <br> Da <br> <br> Ciências Da Computação</h1> <br>
<link rel="stylesheet" href="História.css">
<br>
<br>
<a>Ciência da computação é a ciência que estuda as técnicas, metodologias, instrumentos computacionais e aplicações tecnológicas, que informatizem os processos e desenvolvam
     soluções de processamento de dados de entrada e saída pautados no computador. Não se restringindo apenas ao estudo dos algoritmos, suas aplicações e implementação na
      forma de software. Assim, a Ciência da Computação também abrange as técnicas de modelagem de dados e gerenciamento de banco de dados, envolvendo também a
       telecomunicação e os protocolos de comunicação, além de princípios que abrangem outras especializações da área.

    Enquanto ciência, classifica-se como ciência exata, apesar de herdar elementos da lógica filosófica aristotélica, tendo por isto um papel importante na formalização
     matemática de algoritmos, como forma de representar problemas decidíveis, i.e., os que são susceptíveis de redução a operações elementares básicas, capazes de
      serem reproduzidas através de um dispositivo qualquer capaz de armazenar e manipular dados. Um destes dispositivos é o computador digital, de uso generalizado,
       nos dias de hoje. Também de fundamental importância para a área de Ciência da Computação são as metodologias e técnicas ligadas à implementação de software que
        abordam a especificação, modelagem, codificação, teste e avaliação de sistemas
      de software.
    Os estudos oriundos da Ciência da Computação podem ser aplicados em qualquer área do conhecimento humano em que seja possível definir métodos de resolução de problemas
     baseados em repetições previamente observadas. Avanços recentes na Ciência da Computação têm impactado fortemente a sociedade contemporânea, em particular as aplicações
      relacionadas às áreas de redes de computadores, Internet, Web, ciência de dados e computação móvel, que têm sido utilizadas por bilhões de pessoas ao redor do globo. 
      <br> A primeira ferramenta conhecida para a computação foi o ábaco, cuja invenção é atribuída a habitantes da Mesopotâmia, em torno de 2700–2300 a.C.. Seu uso original
       era desenhar linhas na areia com rochas. Versões mais modernas do ábaco ainda são usadas como instrumento de cálculo.

      No século VII a.C., na antiga Índia, o gramático Pānini formulou a gramática de Sânscrito usando 3959 regras conhecidas como Ashtadhyāyi, de forma bastante sistemática
       e técnica. Pānini usou transformações e recursividade com tamanha sofisticação que sua gramática possuía o poder computacional teórico tal qual a Máquina de Turing.
      Entre 200 a.C. e 400, os indianos também inventaram o logaritmo, e a partir do século XIII tabelas logarítmicas eram produzidas por matemáticos islâmicos. Quando John
       Napier descobriu os logaritmos para uso computacional no século XVI, seguiu-se um período de considerável progresso na construção de ferramentas de cálculo. <br>No 
       século VII, o matemático indiano Brahmagupta explicou pela primeira vez o sistema de numeração hindu-arábico e o uso do 0. Aproximadamente em 825, o matemático persa
        al-Khwarizmi escreveu o livro Calculando com numerais hindus, responsável pela difusão do sistema de numeração hindu-arábico no Oriente Médio, e posteriormente na
         Europa. Por volta do século XII houve uma tradução do mesmo livro para o latim: Algoritmi de numero Indorum. Tais livros apresentaram novos conceitos para definir
          sequências de passos para completar tarefas, como aplicações de aritmética e álgebra. Por derivação do nome do matemático, atualmente usa-se o termo algoritmo. <br>
          Por volta do século III a.C., o matemático indiano Pingala inventou o sistema de numeração binário. Ainda usado atualmente no processamento de todos os computadores
           modernos, o sistema estabelece que sequências específicas de uns e zeros podem representar qualquer informação.

          Em 1703 Gottfried Leibniz desenvolveu a lógica em um sentido formal e matemático, utilizando o sistema binário. Em seu sistema, uns e zeros também representam
           conceitos como verdadeiro e falso, ligado e desligado, válido e inválido. Mais de um século depois, George Boole publicou a álgebra booleana (em 1854), com um 
           sistema completo que permitia a construção de modelos matemáticos para o processamento computacional. Em 1801, apareceu o tear controlado por cartão perfurado,
            invenção de Joseph Marie Jacquard, no qual buracos indicavam os uns e áreas não furadas indicavam os zeros. O sistema está longe de ser um computador, mas ilustrou
             que as máquinas poderiam ser controladas pelo sistema binário. <br> Foi com Charles Babbage que o computador moderno começou a ganhar forma, através de seu
              trabalho no engenho analítico. O equipamento descrito originalmente em 1837, mais de um século antes de seu sucessor, nunca foi construído com sucesso, mas
               possuía todas as funções de um computador moderno. O dispositivo de Babbage se diferenciava por ser programável, algo imprescindível para qualquer computador
                moderno.

             Durante sua colaboração, a matemática Ada Lovelace publicou os primeiros programas de computador em uma série de notas para o engenho analítico. Por isso,
              Lovelace é popularmente considerada como a primeira programadora. <br> Antes da década de 1920, computador era um termo associado a pessoas que realizavam
               cálculos, geralmente liderados por físicos. Milhares de computadores eram empregados em projetos no comércio, governo e sítios de pesquisa. Após a década de
                1920, a expressão máquina computacional começou a ser usada para referir-se a qualquer máquina que realize o trabalho de um profissional, especialmente aquelas
                 de acordo com os métodos da Tese de Church-Turing.

              O termo máquina computacional acabou perdendo espaço para o termo reduzido computador no final da década de 1940, com as máquinas digitais cada vez mais
               difundidas. Alan Turing, conhecido como pai da Ciência da Computação, inventou a Máquina de Turing, que posteriormente evoluiu para o computador moderno. <br>
               Os fundamentos matemáticos da Ciência da Computação moderna começaram a ser definidos por Kurt Gödel com seu teorema da incompletude (1931). Essa teoria mostra
                que existem limites no que pode ser provado ou desaprovado em um sistema formal; isso levou a trabalhos posteriores por Gödel e outros teóricos para definir
                 e descrever tais sistemas formais, incluindo conceitos como recursividade e cálculo lambda.

               Em 1936 Alan Turing e Alonzo Church independentemente, e também juntos, introduziram a formalização de um algoritmo, definindo os limites do que pode ser
                computador e um modelo puramente mecânico para a computação. Tais tópicos são abordados no que atualmente chama-se Tese de Church-Turing, uma hipótese sobre
                 a natureza de dispositivos mecânicos de cálculo. Essa tese define que qualquer cálculo possível pode ser realizado por um algoritmo sendo executado em um
                  computador, desde que haja tempo e armazenamento suficiente para tal. Turing também incluiu na tese uma descrição da Máquina de Turing, que possui uma
                   fita de tamanho infinito e um cabeçote para leitura e escrita que move-se pela fita. Devido ao seu caráter infinito, tal máquina não pode ser construída,
                    mas tal modelo pode simular a computação de qualquer algoritmo executado em um computador moderno. Turing é bastante importante para a Ciência da
                     Computação, tanto que seu nome é usado para o Prêmio Turing e o teste de Turing. Ele contribuiu para a quebra do código da Alemanha pela Grã-Bretanha
                      na Segunda Guerra Mundial, e continuou a projetar computadores e programas de computador pela década de 1940; cometeu suicídio em 1954. <br>Até a década
                       de 1930, engenheiros eletricistas podiam construir circuitos eletrônicos para resolver problemas lógicos e matemáticos, mas a maioria o fazia sem 
                       qualquer processo, de forma particular, sem rigor teórico para tal. Isso mudou com a tese de mestrado de Claude Shannon de 1937, A Symbolic Analysis
                        of Relay and Switching Circuits. Enquanto tomava aulas de Filosofia, Shannon foi exposto ao trabalho de George Boole, e percebeu que poderia aplicar
                         esse aprendizado em conjuntos eletro-mecânicos para resolver problemas. Shannon desenvolveu a teoria da informação no artigo de 1948: A Mathematical
                          Theory of Communication, cujo conteúdo serve como fundamento para áreas como compressão de dados e criptografia. <br>Apesar de sua pequena história
                           enquanto uma disciplina acadêmica, a Ciência da Computação deu origem a diversas contribuições fundamentais para a ciência e para a sociedade. Esta
                            ciência foi responsável pela definição formal de computação e computabilidade, e pela prova da existência de problemas insolúveis ou intratáveis
                             computacionalmente.

                 Também foi possível a construção e formalização do conceito de linguagem de computador, sobretudo linguagem de programação, uma ferramenta para a expressão
                  precisa de informação metodológica flexível o suficiente para ser representada em diversos níveis de abstração.
                          
                          Para outros campos científicos e para a sociedade de forma geral, a Ciência da Computação forneceu suporte para a Revolução Digital, dando origem
                           a Era da Informação.[10] A computação científica é uma área da computação que permite o avanço de estudos como o mapeamento do genoma humano
                            </a>
                            <div class="center">
                                <img src="imagem ciencias comp.jpeg" alt="jpeg"> <img src="imagem ciencias 2.jpeg" alt="jpeg">
                                
                            </div> 
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/mFdUqqwzbVs" title="YouTube video player" frameborder="0" allow="accelerometer;
                             autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
     

